{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all the log files into one\n",
    "df = pd.concat( [ pd.read_csv(f, header=None) for f in os.listdir() if f.endswith('csv')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns =['throttle','theta','session','image_file']\n",
    "#df = df[df.session != '05a68148390e41fa89facaff7154103d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df.session.value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the small sessions as these are normally bad runs\n",
    "bad_sessions = counts[counts < 90].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.session.isin(bad_sessions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_db = dict()\n",
    "for f in tqdm_notebook(df.image_file.tolist()):\n",
    "    image_db[f] = plt.imread(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fliplr_sequence(seq):\n",
    "    return np.fliplr( seq.transpose([1,2,3,0])).transpose([3,0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_idx = df.groupby('session').groups\n",
    "\n",
    "N= 7\n",
    "all_ims, all_thetas, all_throttles=[],[],[]\n",
    "sessions = []\n",
    "\n",
    "for k in tqdm_notebook(session_idx):\n",
    "    idx = session_idx[k]\n",
    "    for j in range(10+N,len(idx)-15):\n",
    "        #seq = [ images[i] for i in \n",
    "        ims = [ df.loc[i].image_file for i in idx[j-N:j] ]\n",
    "        thetas =  df.loc[idx[j]].theta\n",
    "        throttles = df.loc[idx[j]].throttle\n",
    "\n",
    "        #ims = np.array([images[f] for f in ims])\n",
    "\n",
    "\n",
    "        if len(ims) ==N:\n",
    "            all_ims.append(ims)\n",
    "            all_thetas.append(thetas)\n",
    "            all_throttles.append(throttles)\n",
    "            sessions.append(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seq = pd.DataFrame({'session':k,'theta':all_thetas, 'throttle':all_throttles, 'seq':all_ims})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq, test_seq = train_test_split(all_seq,test_size=.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_seq), len(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sequence(sequences, batch_size=32, image_db = image_db):\n",
    "    while True:\n",
    "        X,Y=[],[]\n",
    "        for i, row in sequences.sample(batch_size).iterrows():\n",
    "            seq_ims = row.seq\n",
    "            theta = row.theta\n",
    "            ims = np.array([image_db[f] for f in seq_ims])\n",
    "\n",
    "            if np.random.rand() > .5:\n",
    "                ims = fliplr_sequence(ims)\n",
    "                theta =-1*theta\n",
    "\n",
    "            X.append(ims)\n",
    "            Y.append(theta)\n",
    "        yield np.stack(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = next(gen_sequence(train_seq, batch_size=1))\n",
    "fig, ax = plt.subplots(1,N, figsize=(5*N,N))\n",
    "for k in range(N):\n",
    "    ax[k].imshow(X[0][k])\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Lambda, BatchNormalization, LSTM, TimeDistributed, GRU, Activation,Dropout\n",
    "from keras import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net():\n",
    "    inputs = Input(shape=(120,160,3))\n",
    "    #normalize maybe depends on how the image is loaded\n",
    "    x = Conv2D(4,(3,3), padding='same', activation=None, kernel_initializer='he_normal')(inputs)\n",
    "    x= BatchNormalization()(x)\n",
    "    x = Activation('elu')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(8,(3,3), padding='same', activation=None, kernel_initializer='he_normal')(x)\n",
    "    x= BatchNormalization()(x)\n",
    "    x = Activation('elu')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(16,(3,3), padding='same', activation=None, kernel_initializer='he_normal')(x)\n",
    "    x= BatchNormalization()(x)\n",
    "    x = Activation('elu')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(32,(3,3), padding='same', activation=None, kernel_initializer='he_normal')(x)\n",
    "    x= BatchNormalization()(x)\n",
    "    x = Activation('elu')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(64,(3,3), padding='same', activation=None, kernel_initializer='he_normal')(x)\n",
    "    x= BatchNormalization()(x)\n",
    "    x = Activation('elu')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(128,(3,3), padding='same', activation=None, kernel_initializer='he_normal')(x)\n",
    "    x= BatchNormalization()(x)\n",
    "    x = Activation('elu')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    #x = Dense(64,activation='elu')(x)\n",
    "    #x = Dense(1,activation='elu')(x)\n",
    "    \n",
    "    return Model(inputs=[inputs], outputs=[x])\n",
    "\n",
    "def lstm_net():\n",
    "    inputs = Input(shape=(None,256))\n",
    "    #x = LSTM(128, return_sequences=True, dropout=.1)(inputs)\n",
    "    x = LSTM(96, return_sequences=False, dropout=.1)(inputs)\n",
    "    x = Dense(96,activation='elu', kernel_regularizer=l2(1e-4))(x)\n",
    "    x = Dropout(.2)(x)\n",
    "    #x = Dense(96,activation='elu')(x)\n",
    "    #x = Dropout(.1)(x)\n",
    "    x = Dense(1, activation='tanh')(x)\n",
    "    return Model(inputs=[inputs], outputs=[x])\n",
    "    \n",
    "\n",
    "feature_net = net()\n",
    "test_net =  lstm_net()\n",
    "\n",
    "\n",
    "def merged_model():\n",
    "    inputs = Input(shape=(None,120,160,3))\n",
    "    x = TimeDistributed(feature_net)(inputs)\n",
    "    x = test_net(x)\n",
    "    return Model(inputs=[inputs], outputs=[x])\n",
    "\n",
    "tnet = multi_gpu_model( merged_model())\n",
    "\n",
    "opt = Adam(1e-4)\n",
    "tnet.compile(opt,loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnet.fit_generator(gen_sequence(train_seq,batch_size=64)\n",
    "                   ,steps_per_epoch=len(train_seq)//64\n",
    "                   ,epochs=10\n",
    "                   ,validation_data = gen_sequence(test_seq, batch_size=64)\n",
    "                   ,validation_steps = len(test_seq)//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_net.save('feature_net.h5')\n",
    "test_net.save('test_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = next(gen_sequence(test_seq, batch_size=1))\n",
    "fig, ax = plt.subplots(1,N, figsize=(5*N,N))\n",
    "for k in range(N):\n",
    "    ax[k].imshow(X[0][k])\n",
    "print(tnet.predict(X)[0][0], Y[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
